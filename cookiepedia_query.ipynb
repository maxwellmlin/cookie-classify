{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import utils\n",
    "import csv\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directories(root: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Return a list of directories in a given root directory.\n",
    "\n",
    "    Args:\n",
    "        root: Path to the root directory.\n",
    "\n",
    "    Returns:\n",
    "        A list of directories.\n",
    "    \"\"\"\n",
    "    dirs = []\n",
    "    for item in os.listdir(root):\n",
    "        path = os.path.join(root, item)\n",
    "        if os.path.isdir(path):\n",
    "            dirs.append(path)\n",
    "\n",
    "    return dirs\n",
    "\n",
    "def get_cookies_from_har(file: str) -> list[dict[str, str, str]]:\n",
    "    \"\"\"\n",
    "    Returns a list of cookies from response entries in an HAR file.\n",
    "    [HAR Specification](http://www.softwareishard.com/blog/har-12-spec/).\n",
    "\n",
    "    Args:\n",
    "        file: Path to the HAR file.\n",
    "    Returns:\n",
    "        A list of dictionaries representing all cookies in HTTP responses in that HAR file with domains, where each dictionary holds 3 key-value pairs (Cookie Name, Cookie Value, Cookie Domain).\n",
    "    \"\"\"\n",
    "\n",
    "    cookies = []\n",
    "    data = json.load(open(file, \"r\")) # parses JSON data into Python dictionary\n",
    "    for entry in data[\"log\"][\"entries\"]: # each entry is an HTTP request/response pair\n",
    "        \n",
    "        response = entry[\"response\"] # extract response dictionary\n",
    "\n",
    "        if response.get(\"cookies\"): # response contains cookies\n",
    "            for cookie in response[\"cookies\"]:\n",
    "                # print(cookie)\n",
    "                if cookie.get(\"domain\"): # if cookie has domain\n",
    "                    cookies.append({\"Cookie Name\": cookie[\"name\"], \"Cookie Value\": cookie[\"value\"], \"Cookie Domain\": cookie[\"domain\"]})\n",
    "\n",
    "    return cookies\n",
    "\n",
    "def check_requests(detected_list_from_responses: list[dict[str, str, str]], file: str) -> list[dict[str, str, str]]:\n",
    "    \"\"\"\n",
    "    Returns a list of cookies from request entries in an HAR file that also appeared in a response entry.\n",
    "\n",
    "    Args:\n",
    "        detected_list_from_responses: List of cookies from response entries in an HAR file.\n",
    "        file: Path to the HAR file.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries representing all cookies in HTTP requests in that HAR file, where each dictionary holds 3 key-value pairs (Cookie Name, Cookie Value, Cookie Domain).\n",
    "    \"\"\"\n",
    "\n",
    "    detected_list_from_requests = []\n",
    "    data = json.load(open(file, \"r\")) # parses JSON data into Python dictionary\n",
    "    for entry in data[\"log\"][\"entries\"]: # each entry is an HTTP request/response pair\n",
    "        \n",
    "        request = entry[\"request\"] # extract request dictionary\n",
    "\n",
    "        for cookie in request.get(\"cookies\"):\n",
    "            cookie_names = [d[\"Cookie Name\"] for d in detected_list_from_responses]\n",
    "            if cookie.get(\"name\") in cookie_names: # if cookie name is in list of detected cookies from responses\n",
    "                detected_list_from_requests.append({\"Cookie Name\": cookie[\"name\"], \"Cookie Value\": cookie[\"value\"]})\n",
    "                # add this cookie's domain\n",
    "                detected_list_from_requests[-1][\"Cookie Domain\"] = detected_list_from_responses[cookie_names.index(cookie[\"name\"])][\"Cookie Domain\"]\n",
    "\n",
    "    return detected_list_from_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) 2021-2022 Dino Bollinger, ETH ZÃ¼rich, Information Security Group\n",
    "# Released under the MIT License\n",
    "\"\"\"\n",
    "Parts of the script from this cell taken from cookie_stats.py of CookieBlock-Consent-Crawler.\n",
    "\n",
    "This script takes as input a json file as produced by the script `database_scripts/extract_cookies_from_db.py`,\n",
    "which is a list of cookies with matching consent label declaration.\n",
    "\n",
    "This script can extract a number of additional statistics on this data, such as the majority opinion to\n",
    "the categorisation provided by Cookiepedia, and the ratio of disagreement on the label of a cookie name.\n",
    "\n",
    "Cookiepedia hereby provides a large database of cookies, where each cookie is assigned one out of 5 categories, those being:\n",
    "   1. Strictly Necessary\n",
    "   2. Functional\n",
    "   3. Performance (Analytics)\n",
    "   4. Targeting/Advertising\n",
    "   5. Unknown\n",
    "Where the latter category is usually given when Cookiepedia does not have enough data to form a categorization.\n",
    "\"\"\"\n",
    "# from docopt import docopt\n",
    "import requests\n",
    "import requests.exceptions as rexcepts\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import traceback\n",
    "import logging\n",
    "\n",
    "from enum import IntEnum\n",
    "from typing import Tuple, List, Dict, Optional, Any\n",
    "\n",
    "logger = logging.getLogger(\"stats\")\n",
    "\n",
    "# Lookup dictionary for cookiepedia names\n",
    "cookiepedia_lookup = dict()\n",
    "\n",
    "class CookieCategories(IntEnum):\n",
    "    Unrecognized = -1\n",
    "    Necessary = 0\n",
    "    Functional = 1\n",
    "    Analytical = 2\n",
    "    Advertising = 3\n",
    "    Unknown = 4\n",
    "\n",
    "def simple_get(url) -> Optional[requests.Response]:\n",
    "    \"\"\"\n",
    "    Perform a simple GET request to the target address, and handle errors.\n",
    "    @param url: URL to send the GET request to\n",
    "    @return: Response object, or None if an error occurred\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # fake chrome user agent, required or else Cookiepedia will not respond\n",
    "        headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36\"}\n",
    "        r = requests.get(url, timeout=(15, 15), headers=headers)\n",
    "        return r\n",
    "    except (rexcepts.TooManyRedirects, rexcepts.SSLError,\n",
    "            rexcepts.URLRequired, rexcepts.MissingSchema) as ex:\n",
    "        logger.debug(f\"'{type(ex)}' exception occurred while trying to access: '{url}'\")\n",
    "        return None\n",
    "    except (rexcepts.ConnectionError, rexcepts.Timeout) as ex:\n",
    "        logger.debug(f\"'{type(ex)}' exception occurred while trying to access: '{url}'\")\n",
    "        return None\n",
    "    except Exception as ex:\n",
    "        logger.error(f\"Unexpected '{type(ex)}' exception occurred while trying to access: '{url}'\")\n",
    "        logger.error(traceback.format_exc())\n",
    "        return None\n",
    "    \n",
    "def get_cookiepedia_opinion(cookie_name: str) -> Tuple[CookieCategories, str]:\n",
    "    \"\"\"\n",
    "    Send a request to Cookiepedia to get their category for the given cookie name, if present.\n",
    "    Unknown category, connection errors and cookie not found are all translated to category id -1.\n",
    "    @param cookie_name: Cookie name to retrieve category for.\n",
    "    @return: Tuple of Category ID and Category Name\n",
    "    \"\"\"\n",
    "    if cookie_name in cookiepedia_lookup:\n",
    "        return cookiepedia_lookup[cookie_name]\n",
    "\n",
    "    result = simple_get(f\"https://cookiepedia.co.uk/cookies/{cookie_name}\")\n",
    "\n",
    "    cookiepedia_category: str = \"Not Found\"\n",
    "    if result is not None:\n",
    "        m_obj = re.search(\"The main purpose of this cookie is:\\\\s*<strong>(.*)</strong>\", result.text)\n",
    "        if m_obj is not None:\n",
    "            cookiepedia_category = m_obj.group(1)\n",
    "    else:\n",
    "        cookiepedia_category = \"Connection Failed\"\n",
    "\n",
    "    # Translate string category name to an integer for comparison purposes\n",
    "    cp_id: CookieCategories\n",
    "    if cookiepedia_category == \"Strictly Necessary\":\n",
    "        cp_id = CookieCategories.Necessary\n",
    "    elif cookiepedia_category == \"Functionality\":\n",
    "        cp_id = CookieCategories.Functional\n",
    "    elif cookiepedia_category == \"Performance\":\n",
    "        cp_id = CookieCategories.Analytical\n",
    "    elif cookiepedia_category == \"Targeting/Advertising\":\n",
    "        cp_id = CookieCategories.Advertising\n",
    "    elif re.match(\"(Unknown|Not Found|Connection Failed)\", cookiepedia_category):\n",
    "        cp_id = CookieCategories.Unknown\n",
    "    else:\n",
    "        logger.warning(f\"Unrecognized category name: {cookiepedia_category}\")\n",
    "        cp_id = CookieCategories.Unrecognized\n",
    "\n",
    "    cookiepedia_lookup[cookie_name] = (cp_id, cookiepedia_category)\n",
    "\n",
    "    return cp_id, cookiepedia_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_paths = get_directories(\"crawls/depth0\")\n",
    "\n",
    "# for counting number of inner pages per domain\n",
    "domains_paths_normal = {}\n",
    "domains_paths_reject = {}\n",
    "\n",
    "incomplete_runs = 0\n",
    "total_inner_pages = 0\n",
    "\n",
    "detected_cookies_normal = []\n",
    "detected_cookies_reject = []\n",
    "\n",
    "for site in domain_paths:\n",
    "    inner_site_paths = get_directories(site)\n",
    "    total_inner_pages += len(inner_site_paths)\n",
    "\n",
    "    for inner_site_path in inner_site_paths:\n",
    "        normal_har_path = f\"{inner_site_path}/normal.json\"\n",
    "        reject_har_path = f\"{inner_site_path}/after_reject.json\"\n",
    "\n",
    "        if not os.path.isfile(normal_har_path) or not os.path.isfile(reject_har_path):\n",
    "            # Requires both normal and intercept HAR files to exist\n",
    "            incomplete_runs += 1\n",
    "            continue\n",
    "\n",
    "        domain = site.split(\"/\")[2]\n",
    "\n",
    "        # Append inner site path to the dictionary for normal crawls\n",
    "        if domain in domains_paths_normal:\n",
    "            domains_paths_normal[domain].append(inner_site_path)\n",
    "        else:\n",
    "            domains_paths_normal[domain] = [inner_site_path]\n",
    "\n",
    "        # Append inner site path to the dictionary for after_reject crawls\n",
    "        if domain in domains_paths_reject:\n",
    "            domains_paths_reject[domain].append(inner_site_path)\n",
    "        else:\n",
    "            domains_paths_reject[domain] = [inner_site_path]\n",
    "\n",
    "        cookies_from_responses_normal = get_cookies_from_har(normal_har_path)\n",
    "        # print(cookies_from_responses_normal)\n",
    "        cookies_from_requests_normal = check_requests(cookies_from_responses_normal, normal_har_path)\n",
    "        # print(cookies_from_requests_normal)\n",
    "\n",
    "        # saving cookies from responses for easy parsing into dataframe\n",
    "        for cookie in cookies_from_requests_normal:\n",
    "            detected_cookies_normal.append({\n",
    "                \"Domain\": domain,\n",
    "                \"Inner Site Path\": inner_site_path,\n",
    "                \"Cookie Name\": cookie[\"Cookie Name\"],\n",
    "                \"Cookie Value\": cookie[\"Cookie Value\"],\n",
    "                \"Cookie Domain\": cookie[\"Cookie Domain\"],\n",
    "                \"Cookiepedia Category\": get_cookiepedia_opinion(cookie[\"Cookie Name\"])[1]\n",
    "            })\n",
    "df_detected_cookies_normal = pd.DataFrame(detected_cookies_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Domain               Inner Site Path Cookie Name  \\\n",
      "0          mail.ru       crawls/depth0/mail.ru/0           o   \n",
      "1          mail.ru       crawls/depth0/mail.ru/0        mrhc   \n",
      "2          mail.ru       crawls/depth0/mail.ru/0           i   \n",
      "3          mail.ru       crawls/depth0/mail.ru/0           b   \n",
      "4          mail.ru       crawls/depth0/mail.ru/0         VID   \n",
      "...            ...                           ...         ...   \n",
      "6783  workable.com  crawls/depth0/workable.com/0     __cf_bm   \n",
      "6784  workable.com  crawls/depth0/workable.com/0     __cf_bm   \n",
      "6785  workable.com  crawls/depth0/workable.com/0     __cf_bm   \n",
      "6786  workable.com  crawls/depth0/workable.com/0     __cf_bm   \n",
      "6787  workable.com  crawls/depth0/workable.com/0     __cf_bm   \n",
      "\n",
      "                                           Cookie Value Cookie Domain  \\\n",
      "0                                          :1624:EAg=.m       mail.ru   \n",
      "1          jvHvi8e1FvoeLTGQ7Q8ZyEvqL4aLfIn7VGj7r6JKdEI=       mail.ru   \n",
      "2                      AQBJqbFkAgBdBgUCAQC9BwgEATUTAQ==      .mail.ru   \n",
      "3                                      X0wBAAA1EwoEAQAC      .mail.ru   \n",
      "4     2Yqr0609RoYI00000t1kP4oI:::0-0-0-9cc0211:CAASE...      .mail.ru   \n",
      "...                                                 ...           ...   \n",
      "6783  EnSvwqo7gpt8ZLO201X8X9bQRTzrD0YzJQphcO5TAXE-16...  .hubspot.com   \n",
      "6784  EnSvwqo7gpt8ZLO201X8X9bQRTzrD0YzJQphcO5TAXE-16...  .hubspot.com   \n",
      "6785  EnSvwqo7gpt8ZLO201X8X9bQRTzrD0YzJQphcO5TAXE-16...  .hubspot.com   \n",
      "6786  EnSvwqo7gpt8ZLO201X8X9bQRTzrD0YzJQphcO5TAXE-16...  .hubspot.com   \n",
      "6787  EnSvwqo7gpt8ZLO201X8X9bQRTzrD0YzJQphcO5TAXE-16...  .hubspot.com   \n",
      "\n",
      "     Cookiepedia Category  \n",
      "0                 Unknown  \n",
      "1               Not Found  \n",
      "2                 Unknown  \n",
      "3                 Unknown  \n",
      "4                 Unknown  \n",
      "...                   ...  \n",
      "6783            Not Found  \n",
      "6784            Not Found  \n",
      "6785            Not Found  \n",
      "6786            Not Found  \n",
      "6787            Not Found  \n",
      "\n",
      "[6788 rows x 6 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6788 entries, 0 to 6787\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   Domain                6788 non-null   object\n",
      " 1   Inner Site Path       6788 non-null   object\n",
      " 2   Cookie Name           6788 non-null   object\n",
      " 3   Cookie Value          6788 non-null   object\n",
      " 4   Cookie Domain         6788 non-null   object\n",
      " 5   Cookiepedia Category  6788 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 318.3+ KB\n",
      "None\n",
      "Cookiepedia Category\n",
      "Unknown                  3453\n",
      "Targeting/Advertising    2127\n",
      "Not Found                 653\n",
      "Performance               308\n",
      "Strictly Necessary        140\n",
      "Functionality             107\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_detected_cookies_normal)\n",
    "print(df_detected_cookies_normal.info())\n",
    "category_counts = df_detected_cookies_normal['Cookiepedia Category'].value_counts()\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store the JSON data\n",
    "json_data = {}\n",
    "\n",
    "# Define a mapping of Cookiepedia Category values to labels\n",
    "category_mapping = {\n",
    "    \"Strictly Necessary\": 0,\n",
    "    \"Functionality\": 1,\n",
    "    \"Performance\": 1,\n",
    "    \"Targeting/Advertising\": 2,\n",
    "    \"Unknown\": 4,\n",
    "    \"Not Found\": -1\n",
    "}\n",
    "\n",
    "# Iterate through the rows of the DataFrame\n",
    "for index, row in df_detected_cookies_normal.iterrows():\n",
    "    # Construct the cookie_id\n",
    "    cookie_id = f\"{row['Cookie Name']};{row['Cookie Domain']};{'/'};{row['Domain']}\"\n",
    "\n",
    "    # Determine the label based on Cookiepedia Category\n",
    "    label = category_mapping.get(row['Cookiepedia Category'], -1)\n",
    "\n",
    "    # Create a dictionary for the cookie data\n",
    "    cookie_data = {\n",
    "        \"name\": row['Cookie Name'],\n",
    "        \"domain\": row['Cookie Domain'],\n",
    "        \"path\": '/',\n",
    "        \"first_party_domain\": row['Domain'],\n",
    "        \"cmp_origin\": 1,\n",
    "        \"label\": label,\n",
    "        \"variable_data\": [{\n",
    "            \"value\": row['Cookie Value'],\n",
    "            \"expiry\": 0,  # FIXME: don't have this value\n",
    "            \"session\": False,    # FIXME: replace\n",
    "            \"http_only\": True, # FIXME: replace\n",
    "            \"host_only\": False, # FIXME: replace\n",
    "            \"secure\": False, # FIXME: replace\n",
    "            \"same_site\": False # FIXME: replace\n",
    "        }]\n",
    "    }\n",
    "\n",
    "    # Add the cookie data to the JSON dictionary using the cookie_id as the key\n",
    "    json_data[cookie_id] = cookie_data\n",
    "\n",
    "# Convert the JSON data to a JSON string\n",
    "json_string = json.dumps(json_data, indent=2)\n",
    "\n",
    "# Save the JSON data to a file\n",
    "with open('output.json', 'w') as json_file:\n",
    "    json_file.write(json_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cookie-classify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
