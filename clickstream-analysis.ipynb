{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_shingle import ImageShingle\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRAWL_NAME = 'sep10-clickstream'\n",
    "CRAWL_PATH = f'crawls/{CRAWL_NAME}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directories(root: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Return a list of directories in a given root directory.\n",
    "\n",
    "    Args:\n",
    "        root: Path to the root directory.\n",
    "\n",
    "    Returns:\n",
    "        A list of directories.\n",
    "    \"\"\"\n",
    "    dirs = []\n",
    "    for item in os.listdir(root):\n",
    "        path = os.path.join(root, item)\n",
    "        if os.path.isdir(path):\n",
    "            dirs.append(path)\n",
    "\n",
    "    return dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 website  website_similarity  sample_size\n",
      "0                mail.ru            0.425397            6\n",
      "1                zoom.us            0.583210           32\n",
      "2              europa.eu            0.898231           74\n",
      "3           digicert.com            1.000000            2\n",
      "4      stackoverflow.com            0.754009           31\n",
      "5           amazon.co.uk            0.975000            1\n",
      "6                 hp.com            0.767481           44\n",
      "7             aliyun.com            0.741929           54\n",
      "8          rackspace.com            0.522734           43\n",
      "9            freepik.com            0.734762           17\n",
      "10          springer.com            0.867038           83\n",
      "11            nature.com            0.751446           62\n",
      "12       casalemedia.com            0.973354           44\n",
      "13      surveymonkey.com            0.754694           24\n",
      "14  paloaltonetworks.com            0.327937            5\n",
      "15            nvidia.com            0.360317            2\n",
      "16           imgsmail.ru            0.397321            7\n",
      "17          verisign.com            1.000000           10\n",
      "18             swrve.com            0.700531           42\n",
      "19      businesswire.com            1.000000            4\n",
      "20          deloitte.com            0.220635            1\n",
      "21                rt.com            0.672011           58\n",
      "22            docker.com            0.673868           82\n",
      "23            ebay.co.uk            0.655389           36\n",
      "24              plos.org            0.236332           76\n",
      "25      doubleverify.com            0.940222          100\n",
      "26               bmj.com            0.559318           62\n",
      "27           gartner.com            0.285714            1\n"
     ]
    }
   ],
   "source": [
    "rows_list = []\n",
    "\n",
    "for path in get_directories(CRAWL_PATH):\n",
    "    clickstreams = get_directories(path)\n",
    "\n",
    "    sample_size = 0\n",
    "\n",
    "    total_clickstreams = 0\n",
    "    website_sum = 0\n",
    "\n",
    "    for clickstream in clickstreams:\n",
    "\n",
    "        total_actions = 0\n",
    "        clickstream_sum = 0\n",
    "\n",
    "        for _ in range(10):\n",
    "            all_cookies_path = f\"{clickstream}/all_cookies-{total_actions}.png\"\n",
    "            no_cookies_path = f\"{clickstream}/no_cookies-{total_actions}.png\"\n",
    "            \n",
    "            if os.path.isfile(all_cookies_path) and os.path.isfile(no_cookies_path):\n",
    "                CHUNK_SIZE = 40  # Recommended by https://www.usenix.org/legacy/events/sec07/tech/full_papers/anderson/anderson.pdf\n",
    "                all_cookies_shingle = ImageShingle(all_cookies_path, 40)\n",
    "                no_cookies_shingle = ImageShingle(no_cookies_path, 40)\n",
    "\n",
    "                clickstream_sum += all_cookies_shingle.compare(no_cookies_shingle)\n",
    "                total_actions += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        sample_size += total_actions\n",
    "\n",
    "        if total_actions != 0:\n",
    "            clickstream_similarity = clickstream_sum / total_actions\n",
    "            website_sum += clickstream_similarity\n",
    "\n",
    "            total_clickstreams += 1\n",
    "    \n",
    "    if total_clickstreams != 0:\n",
    "        website_similarity = website_sum / total_clickstreams\n",
    "\n",
    "        website = os.path.basename(os.path.normpath(path))\n",
    "        rows_list.append({\n",
    "            \"website\": website,\n",
    "            \"website_similarity\": website_similarity,\n",
    "            \"sample_size\": sample_size\n",
    "        })\n",
    "        \n",
    "df = pd.DataFrame(rows_list)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['sample_size'], ascending=False)\n",
    "df.to_csv(f'analysis/{CRAWL_NAME}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cookie-classify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
