{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.image_shingle import ImageShingle\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import utils.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "CRAWL_NAME = 'clickstream-multiple-sc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRAWL_PATH = f'crawls/{CRAWL_NAME}/'\n",
    "PATHS = []\n",
    "with open(f\"crawls/{CRAWL_NAME}/results.json\") as results:\n",
    "    results = json.load(results)\n",
    "    for path in results:\n",
    "        if results[path][\"crawl_failure\"] is False:\n",
    "            PATHS.append(path)\n",
    "\n",
    "print(len(PATHS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_clickstreams(baseline: str, comparison: str, name: str) -> pd.DataFrame:\n",
    "    rows_list = []\n",
    "\n",
    "    for i, path in enumerate(PATHS):\n",
    "        print(f\"Analyzing site {i+1}/{len(PATHS)}\")\n",
    "        clickstreams = utils.get_directories(path)\n",
    "\n",
    "        sample_size = 0\n",
    "\n",
    "        total_clickstreams = 0\n",
    "        website_sum = 0\n",
    "\n",
    "        for clickstream in clickstreams:\n",
    "\n",
    "            total_actions = 0\n",
    "            clickstream_sum = 0\n",
    "\n",
    "            for _ in range(10):\n",
    "                baseline_base_path = f\"{clickstream}/{baseline}-{total_actions}\"\n",
    "                comparison_path = f\"{clickstream}/{comparison}-{total_actions}.png\"\n",
    "                \n",
    "                if os.path.isfile(comparison_path):\n",
    "                    comparison_shingle = ImageShingle(comparison_path)\n",
    "\n",
    "                    max_similarity = 0\n",
    "                    for i in range(1, 11):\n",
    "                        baseline_path = f\"{baseline_base_path}-{i}.png\"                        \n",
    "                        if os.path.isfile(baseline_path):\n",
    "                            baseline_shingle = ImageShingle(baseline_path)\n",
    "                            max_similarity = max(max_similarity, baseline_shingle.compare(comparison_shingle))\n",
    "\n",
    "                    clickstream_sum += max_similarity\n",
    "                    total_actions += 1\n",
    "\n",
    "            sample_size += total_actions\n",
    "\n",
    "            if total_actions != 0:\n",
    "                clickstream_similarity = clickstream_sum / total_actions\n",
    "                website_sum += clickstream_similarity\n",
    "\n",
    "                total_clickstreams += 1\n",
    "        \n",
    "        if total_clickstreams != 0:\n",
    "            website_similarity = website_sum / total_clickstreams\n",
    "            website_difference = 1 - website_similarity\n",
    "\n",
    "            website = os.path.basename(os.path.normpath(path))\n",
    "            rows_list.append({\n",
    "                \"website\": website,\n",
    "                f\"difference_{name}\": website_difference,\n",
    "                f\"sample_size_{name}\": sample_size\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_with_control() -> pd.DataFrame:\n",
    "    rows_list = []\n",
    "\n",
    "    for i, path in enumerate(PATHS):\n",
    "        print(f\"{i+1}/{len(PATHS)} completed\")\n",
    "\n",
    "        clickstreams = utils.get_directories(path)\n",
    "\n",
    "        sample_size = 0\n",
    "\n",
    "        total_clickstreams = 0\n",
    "        website_sum = 0\n",
    "\n",
    "        for clickstream in clickstreams:\n",
    "\n",
    "            total_actions = 0\n",
    "            clickstream_sum = 0\n",
    "\n",
    "            for _ in range(10):\n",
    "                baseline_base_path = f\"{clickstream}/baseline-{total_actions}\"\n",
    "                control_path = f\"{clickstream}/control-{total_actions}.png\"\n",
    "                experimental_path = f\"{clickstream}/experimental-{total_actions}.png\"\n",
    "                \n",
    "                if os.path.isfile(control_path) and os.path.isfile(experimental_path):\n",
    "                    baseline_shingles = []\n",
    "                    for i in range(1, 11):\n",
    "                        baseline_path = f\"{baseline_base_path}-{i}.png\"\n",
    "                        if os.path.isfile(baseline_path):\n",
    "                            baseline_shingles.append(ImageShingle(baseline_path))\n",
    "\n",
    "                    control_shingle = ImageShingle(control_path)\n",
    "                    experimental_shingle = ImageShingle(experimental_path)\n",
    "\n",
    "                    try:\n",
    "                        clickstream_sum += ImageShingle.compare_with_controls(baseline_shingles, control_shingle, experimental_shingle)\n",
    "                    except:\n",
    "                        print(baseline_shingles)\n",
    "                    total_actions += 1\n",
    "\n",
    "            sample_size += total_actions\n",
    "\n",
    "            if total_actions != 0:\n",
    "                clickstream_similarity = clickstream_sum / total_actions\n",
    "                website_sum += clickstream_similarity\n",
    "\n",
    "                total_clickstreams += 1\n",
    "        \n",
    "        if total_clickstreams != 0:\n",
    "            website_similarity = website_sum / total_clickstreams\n",
    "            website_difference = 1 - website_similarity\n",
    "\n",
    "            website = os.path.basename(os.path.normpath(path))\n",
    "            rows_list.append({\n",
    "                \"website\": website,\n",
    "                f\"difference\": website_difference,\n",
    "                f\"sample_size\": sample_size\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/25 completed\n",
      "2/25 completed\n",
      "3/25 completed\n",
      "4/25 completed\n",
      "5/25 completed\n",
      "6/25 completed\n",
      "7/25 completed\n",
      "8/25 completed\n",
      "9/25 completed\n",
      "10/25 completed\n",
      "11/25 completed\n",
      "12/25 completed\n",
      "13/25 completed\n",
      "14/25 completed\n",
      "15/25 completed\n",
      "16/25 completed\n",
      "17/25 completed\n",
      "18/25 completed\n",
      "19/25 completed\n",
      "20/25 completed\n",
      "21/25 completed\n",
      "22/25 completed\n",
      "23/25 completed\n",
      "24/25 completed\n",
      "25/25 completed\n",
      "1/25 completed\n",
      "2/25 completed\n",
      "3/25 completed\n",
      "4/25 completed\n",
      "5/25 completed\n",
      "6/25 completed\n",
      "7/25 completed\n",
      "8/25 completed\n",
      "9/25 completed\n",
      "10/25 completed\n",
      "11/25 completed\n",
      "12/25 completed\n",
      "13/25 completed\n",
      "14/25 completed\n",
      "15/25 completed\n",
      "16/25 completed\n",
      "17/25 completed\n",
      "18/25 completed\n",
      "19/25 completed\n",
      "20/25 completed\n",
      "21/25 completed\n",
      "22/25 completed\n",
      "23/25 completed\n",
      "24/25 completed\n",
      "25/25 completed\n"
     ]
    }
   ],
   "source": [
    "# Two comparison algorithm\n",
    "control = compare_clickstreams(\"baseline\", \"control\", \"control\")\n",
    "experimental = compare_clickstreams(\"baseline\", \"experimental\", \"remove_cookies\")\n",
    "merged_df = control.merge(experimental, on=[\"website\"])\n",
    "\n",
    "# One comparison algorithm\n",
    "control_comparison = compare_with_control()\n",
    "merged_df = merged_df.merge(control_comparison, on=[\"website\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(f'analysis/{CRAWL_NAME}-two-comparisons.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cookie-classify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
